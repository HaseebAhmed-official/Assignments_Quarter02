{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkXLUaR2osvCiche1c3hBL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaseebAhmed-official/Assignments_Quarter02/blob/main/Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NOTE:**\n",
        "\n",
        "**I gave it my all** and **conclude** that first of all **Openai,claude ai,mistral ai they all are paid** and for **gemini** it **also** reqiures *PROJECT_ID,CREDEDENTIALS etc* enviroment variable along with API,and i **also** tried **some other** but they **did'nt work** with aisiute **except** \"*groq*\" model I also tried\"***Huggingface***\" and **it worked separately** as you can scroll down and can see in cell named as \"***Working separately but not with aisiute***\"."
      ],
      "metadata": {
        "id": "C3W7QWpTVaO6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "collapsed": true,
        "id": "r5L7F2k2BEaw"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q aisuite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q groq"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4TDSP3BKBYJ7"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key2=userdata.get('GROQ_API_KEY')\n",
        "if api_key2:\n",
        "  print('GROQ_API_KEY is set')\n",
        "else:\n",
        "  print('GROQ_API_KEY is not set')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPqEQKHfQEtU",
        "outputId": "f59a17b7-5388-4b91-c1c0-565982113954"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROQ_API_KEY is set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GROQ_API_KEY'] = api_key2"
      ],
      "metadata": {
        "id": "JzwFGiw2Broi"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getenv(\"GROQ_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "cm9U6gX-QjHz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import aisuite as ai\n",
        "client = ai.Client()\n",
        "Model = \"groq:llama3-groq-70b-8192-tool-use-preview\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
        "]\n",
        "response = client.chat.completions.create(\n",
        "        model=Model,\n",
        "        messages=messages,\n",
        "        temperature=0.75\n",
        "    )\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu1x5V5AUDOr",
        "outputId": "6155ff84-d83c-44e8-c5eb-8a4cc6e348e9"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahoy, matey! Why did the scurvy dog go to the vet? Because it had a ruff day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OTHER MODEL**"
      ],
      "metadata": {
        "id": "sTBme9opZswb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q huggingface_hub"
      ],
      "metadata": {
        "id": "cXRUVo_8Jj6P",
        "collapsed": true
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key1=userdata.get('HUGGINGFACE_TOKEN')\n",
        "if api_key1:\n",
        "  print('HUGGINGFACE_TOKEN is set')\n",
        "else:\n",
        "  print('HUGGINGFACE_TOKEN is not set')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDdRJxN-Blob",
        "outputId": "0068591d-4bbd-4ddf-f216-f6fe129a639e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HUGGINGFACE_TOKEN is set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACE_TOKEN'] =api_key1"
      ],
      "metadata": {
        "id": "APWG8B1OVDr_"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Working separately but not with aisiute**"
      ],
      "metadata": {
        "id": "hHCDZBOUWtdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Your Hugging Face API token\n",
        "api_token = \"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\"\n",
        "\n",
        "# Set up the headers\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_token}\"\n",
        "}\n",
        "\n",
        "# Define the request payload (example for text generation)\n",
        "payload = {\n",
        "    \"inputs\": \"Tell me a pirate joke.\",\n",
        "    \"parameters\": {\"temperature\": 0.75}\n",
        "}\n",
        "\n",
        "# Call the Hugging Face Inference API\n",
        "response = requests.post(\n",
        "    \"https://api-inference.huggingface.co/models/meta-llama/Llama-3.3-70B-Instruct\",\n",
        "    headers=headers,\n",
        "    json=payload\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.status_code)\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwosqVv0WFUD",
        "outputId": "deaeb583-64ec-4275-c2cc-1cff57b297ed"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n",
            "{'error': 'Model requires a Pro subscription; check out hf.co/pricing to learn more. Make sure to include your HF token in your query.'}\n"
          ]
        }
      ]
    }
  ]
}